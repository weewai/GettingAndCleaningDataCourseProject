<html>

<body>
<h2>Datasets</h2>

<p>Downloaded unzipped:</p>

<ul>
<li>data/Dataset.zip: downloaded from the Internet</li>
<li>&ldquo;UCI HAR Dataset&rdquo;: folder unzipped from Dataset.zip</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/activity_labels.txt: labels for each of the 6 activities (loaded by run_analysis.R)</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/features.txt: labels for each measurement found in the test and training datasets (loaded by run_analysis.R)</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/train/subject_train.txt: subjects ID corresponding to the training dataset (loaded by run_analysis.R)</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/train/X_train.txt: the training dataset, containing measurements only (loaded by run_analysis.R)</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/train/y_train.txt: activities codes for the training dataset (loaded by run_analysis.R)</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/test/subject_test.txt: subjects ID corresponding to the test dataset (loaded by run_analysis.R)</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/test/X_test.txt: the test dataset, containing measurements only (loaded by run_analysis.R)</li>
<li>&ldquo;UCI HAR Dataset&rdquo;/test/y_test.txt: activities codes for the test dataset (loaded by run_analysis.R)</li>
</ul>

<p>Generated by the script:</p>

<ul>
<li>data/tidy.txt: output of the project generated by run_analysis.R; contains a header and 180 rows (30 subjects x 6 activities)</li>
</ul>

<h2>Variables Description</h2>

<p>Result dataset: tidy.txt</p>

<ul>
<li>Subject: subject ID, comes from subject_train.txt and subject_test.txt files</li>
<li>Activity: activity as a factor, comes from y_train.txt and y_test.txt files</li>
<li>All mean measurements in the form ID-(mean|std)[-X|Y|Z], e.g fBodyAcc-mean-X, fBodyBodyGyroMag-std. There are 66 measurements in the tidy.txt dataset. The original measurements come from X_train.txt and X_test.txt.</li>
</ul>

<h2>Transformations</h2>

<p>The following steps are performed by run_analysis.R to generate tidy.txt:</p>

<ul>
<li>a. cleanup </li>
<li>b. fetch and unzip the data set</li>
<li>b.1 create data sub-directory if necessary</li>
<li>b.2 download original data if necessary (skip if exists already as it takes time)</li>
<li>c. read the data sets</li>
<li>c.1 subjects IDs</li>
<li>c.1 activities codes</li>
<li>c.2 measurements</li>
<li>d. merge datasets vertically, adding rows but keeping the same columns</li>
<li>d.1 subjects</li>
<li>d.2 activity codes</li>
<li>d.3 measurements</li>
<li>e. read feature and activity labels</li>
<li>e.1 read as-is</li>
<li>e.2 add column names and check</li>
<li>f. renames columns of the merged measurement dataset with the feature labels</li>
<li>g. filter the merged dataset to keep names with mean() or std() in them</li>
<li>g.1 select the columns to keep</li>
<li>g.2 subset by keeping the columns</li>
<li>g.3. remove the parenthesis from the names</li>
<li>h. add Subject and Activity columns in front</li>
<li>i. add activity labels to the merged dataset (Activity becomes a <em>factor</em>)</li>
<li>j. aggregate and calculate the mean by subject and activity</li>
<li>k. save the tidy dataset in data (note: Activiti is save as a factor)</li>
</ul>

<p>These steps are clearly documented in run_analysis.R</p>

</body>

</html>